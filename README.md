# Transformer-attention
compare the theory attention gradient with PyTorch attention gradient

- If you want see the detail calcualtion,please see [CN](https://zhuanlan.zhihu.com/p/562061005),[EN](https://say-hello2y.github.io/2022-09-07/attention-gradient)
  